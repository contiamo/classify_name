{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "import torch\n",
    "import typing\n",
    "import unicodedata\n",
    "\n",
    "nn = torch.nn\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "bundle_root = pathlib.Path(os.environ.get('LABS_BUNDLE_ROOT', '/labs'))\n",
    "sys.path.append(str(bundle_root / 'functions'))\n",
    "sys.path.append(str(bundle_root /  'common'))\n",
    "import utils\n",
    "importlib.reload(utils);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base classe\n",
    "RNN = utils.RNN\n",
    "# init model\n",
    "rnn = RNN(utils.n_letters, utils.n_hidden, utils.n_categories)\n",
    "# fill in weights\n",
    "rnn.load_state_dict(torch.load(str(bundle_root / 'common/char-rnn-classification.pt')))\n",
    "\n",
    "def predict(line: str, n_predictions: int=3) -> typing.List[typing.Tuple]:\n",
    "    output = utils.evaluate(Variable(utils.lineToTensor(line)), rnn)\n",
    "\n",
    "    # Get top N categories\n",
    "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
    "    predictions: List[Any] = []\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i]\n",
    "        category_index = topi[0][i]\n",
    "        predictions += [(str(value).split('tensor')[1], utils.all_categories[category_index])]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_nationality(name: str) -> pd.DataFrame:\n",
    "    #print(name)\n",
    "    name = name.strip()\n",
    "    df_l = []\n",
    "    name_l = name.split(' ')\n",
    "    if '' in name_l:\n",
    "        name_l.remove('')\n",
    "    for name in name_l:\n",
    "        #print(name)\n",
    "        try:\n",
    "            s = predict(name)\n",
    "        except:            \n",
    "            s = ['(0)', 'Unknown']\n",
    "        df_l += [pd.DataFrame([(float(t[0][1:-1]), t[1]) for t in s])]\n",
    "    return pd.concat(df_l).groupby(1)[0].sum().sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add nationality column to crew list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = pd.read_parquet(bundle_root / 'data/processed/crew.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "crew = crew.assign(nationality = lambda s:s['name_'].apply(get_name_nationality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew.to_parquet(bundle_root / 'common/crew_with_nationality.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
