{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Classifying Names with a Character-Level RNN\n",
    "*********************************************\n",
    "We will be building and training a basic character-level RNN to classify\n",
    "words. A character-level RNN reads words as a series of characters -\n",
    "outputting a prediction and \"hidden state\" at each step, feeding its\n",
    "previous hidden state into each next step. We take the final prediction\n",
    "to be the output, i.e. which class the word belongs to.\n",
    "\n",
    "Specifically, we'll train on a few thousand surnames from 18 languages\n",
    "of origin, and predict which language a name is from based on the\n",
    "spelling:\n",
    "\n",
    "::\n",
    "\n",
    "    $ python predict.py Hinton\n",
    "    (-0.47) Scottish\n",
    "    (-1.52) English\n",
    "    (-3.57) Irish\n",
    "\n",
    "    $ python predict.py Schmidhuber\n",
    "    (-0.19) German\n",
    "    (-2.48) Czech\n",
    "    (-2.68) Dutch\n",
    "\n",
    "\n",
    "**Recommended Reading:**\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and\n",
    "understand Tensors:\n",
    "\n",
    "-  http://pytorch.org/ For installation instructions\n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
    "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
    "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
    "\n",
    "It would also be useful to know about RNNs and how they work:\n",
    "\n",
    "-  `The Unreasonable Effectiveness of Recurrent Neural\n",
    "   Networks <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n",
    "   shows a bunch of real life examples\n",
    "-  `Understanding LSTM\n",
    "   Networks <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n",
    "   is about LSTMs specifically but also informative about RNNs in\n",
    "   general\n",
    "\n",
    "Preparing the Data\n",
    "==================\n",
    "\n",
    ".. Note::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n",
    "Included in the ``data/names`` directory are 18 text files named as\n",
    "\"[Language].txt\". Each file contains a bunch of names, one name per\n",
    "line, mostly romanized (but we still need to convert from Unicode to\n",
    "ASCII).\n",
    "\n",
    "We'll end up with a dictionary of lists of names per language,\n",
    "``{language: [names ...]}``. The generic variables \"category\" and \"line\"\n",
    "(for language and name in our case) are used for later extensibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "import torch\n",
    "import unicodedata\n",
    "\n",
    "nn = torch.nn\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from pathlib import PurePath, Path\n",
    "\n",
    "bundle_root = os.environ.get('LABS_BUNDLE_ROOT', '/labs')\n",
    "sys.path.append(str(PurePath(bundle_root, 'functions')))\n",
    "sys.path.append(str(PurePath(bundle_root, 'common')))\n",
    "import utils\n",
    "importlib.reload(utils);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n",
      "Irish\n",
      "Japanese\n",
      "Greek\n",
      "Polish\n",
      "Russian\n",
      "Vietnamese\n",
      "French\n",
      "English\n",
      "Dutch\n",
      "Italian\n",
      "Scottish\n",
      "Portuguese\n",
      "Arabic\n",
      "Spanish\n",
      "Chinese\n",
      "German\n",
      "Czech\n",
      "Korean\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for path in Path(bundle_root, 'data/raw/names').glob('*.txt'):\n",
    "    path = str(path)\n",
    "    category = path.split('/')[-1].split('.')[0]\n",
    "    print(category)\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(path)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning Names into Tensors\n",
    "--------------------------\n",
    "\n",
    "Now that we have all the names organized, we need to turn them into\n",
    "Tensors to make any use of them.\n",
    "\n",
    "To represent a single letter, we use a \"one-hot vector\" of size\n",
    "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
    "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix\n",
    "``<line_length x 1 x n_letters>``.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in\n",
    "batches - we're just using a batch size of 1 here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Network\n",
    "====================\n",
    "\n",
    "Before autograd, creating a recurrent neural network in Torch involved\n",
    "cloning the parameters of a layer over several timesteps. The layers\n",
    "held hidden state and gradients which are now entirely handled by the\n",
    "graph itself. This means you can implement a RNN in a very \"pure\" way,\n",
    "as regular feed-forward layers.\n",
    "\n",
    "This RNN module (mostly copied from `the PyTorch for Torch users\n",
    "tutorial <http://pytorch.org/tutorials/beginner/former_torchies/\n",
    "nn_tutorial.html#example-2-recurrent-net>`__)\n",
    "is just 2 linear layers which operate on an input and hidden state, with\n",
    "a LogSoftmax layer after the output.\n",
    "\n",
    ".. figure:: https://i.imgur.com/Z2xbySO.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "rnn = utils.RNN(utils.n_letters, utils.n_hidden, utils.n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a step of this network we need to pass an input (in our case, the\n",
    "Tensor for the current letter) and a previous hidden state (which we\n",
    "initialize as zeros at first). We'll get back the output (probability of\n",
    "each language) and a next hidden state (which we keep for the next\n",
    "step).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = letterToTensor('A')\n",
    "hidden =torch.zeros(1, utils.n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of efficiency we don't want to be creating a new Tensor for\n",
    "every step, so we will use ``lineToTensor`` instead of\n",
    "``letterToTensor`` and use slices. This could be further optimized by\n",
    "pre-computing batches of Tensors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9109, -2.8608, -2.9291, -2.8575, -2.8849, -2.8894, -2.7882, -3.0109,\n",
      "         -2.9127, -2.8571, -2.8505, -2.9609, -2.8951, -2.9014, -2.9957, -2.8754,\n",
      "         -2.8739, -2.8003]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, utils.n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the output is a ``<1 x n_categories>`` Tensor, where\n",
    "every item is the likelihood of that category (higher is more likely).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "========\n",
    "Preparing for Training\n",
    "----------------------\n",
    "\n",
    "Before going into training we should make a few helper functions. The\n",
    "first is to interpret the output of the network, which we know to be a\n",
    "likelihood of each category. We can use ``Tensor.topk`` to get the index\n",
    "of the greatest value:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('French', 6)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also want a quick way to get a training example (a name and its\n",
    "language):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = French / line = Tremble\n",
      "category = Italian / line = Arlotti\n",
      "category = Portuguese / line = Gaspar\n",
      "category = Dutch / line = Seghers\n",
      "category = Vietnamese / line = Ngo\n",
      "category = Polish / line = Szweda\n",
      "category = Japanese / line = Shibasawa\n",
      "category = Vietnamese / line = Doan\n",
      "category = Arabic / line = Seif\n",
      "category = Czech / line = Swatchak\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network\n",
    "--------------------\n",
    "\n",
    "Now all it takes to train this network is show it a bunch of examples,\n",
    "have it make guesses, and tell it if it's wrong.\n",
    "\n",
    "For the loss function ``nn.NLLLoss`` is appropriate, since the last\n",
    "layer of the RNN is ``nn.LogSoftmax``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each loop of training will:\n",
    "\n",
    "-  Create input and target tensors\n",
    "-  Create a zeroed initial hidden state\n",
    "-  Read each letter in and\n",
    "\n",
    "   -  Keep hidden state for next letter\n",
    "\n",
    "-  Compare final output to target\n",
    "-  Back-propagate\n",
    "-  Return the output and loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to run that with a bunch of examples. Since the\n",
    "``train`` function returns both the output and loss we can print its\n",
    "guesses and also keep track of loss for plotting. Since there are 1000s\n",
    "of examples we print only every ``print_every`` examples, and take an\n",
    "average of the loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0% (0m 0s) 1.5236 Herten / Dutch ✓\n",
      "1000 1% (0m 1s) 1.7446 Paszek / Polish ✓\n",
      "1500 1% (0m 2s) 2.8288 Mata / Japanese ✗ (Portuguese)\n",
      "2000 2% (0m 2s) 1.1672 Yun / Chinese ✗ (Korean)\n",
      "2500 2% (0m 3s) 1.0734 Samaha / Japanese ✗ (Arabic)\n",
      "3000 3% (0m 4s) 1.1756 Si / Korean ✓\n",
      "3500 3% (0m 4s) 0.9341 Mizutani / Japanese ✓\n",
      "4000 4% (0m 5s) 3.2299 Tuma / Vietnamese ✗ (Arabic)\n",
      "4500 4% (0m 6s) 2.3222 Lawerenz / Spanish ✗ (German)\n",
      "5000 5% (0m 6s) 1.8224 Adamou / Greek ✓\n",
      "5500 5% (0m 7s) 2.3039 Bokhoven / Polish ✗ (Dutch)\n",
      "6000 6% (0m 8s) 2.4256 Jurbin / Scottish ✗ (Russian)\n",
      "6500 6% (0m 8s) 2.3088 Harybin / Irish ✗ (Russian)\n",
      "7000 7% (0m 9s) 1.7628 Franco / Spanish ✗ (Portuguese)\n",
      "7500 7% (0m 10s) 0.9914 Capello / Italian ✓\n",
      "8000 8% (0m 10s) 1.8325 Savatier / French ✓\n",
      "8500 8% (0m 11s) 2.0250 Olivier / German ✗ (French)\n",
      "9000 9% (0m 12s) 2.3283 Kilmurry / Czech ✗ (English)\n",
      "9500 9% (0m 13s) 2.0144 Han / Chinese ✗ (Korean)\n",
      "10000 10% (0m 13s) 2.2899 Gorsky / Polish ✗ (Russian)\n",
      "10500 10% (0m 14s) 3.5851 Villalobos / Greek ✗ (Spanish)\n",
      "11000 11% (0m 15s) 1.0223 Que / Chinese ✓\n",
      "11500 11% (0m 15s) 2.1528 Close / Scottish ✗ (Greek)\n",
      "12000 12% (0m 16s) 1.1632 O'Hannigain / Irish ✓\n",
      "12500 12% (0m 17s) 0.4372 Airaldi / Italian ✓\n",
      "13000 13% (0m 17s) 0.5604 Rudaski / Polish ✓\n",
      "13500 13% (0m 18s) 1.0938 Marion / French ✓\n",
      "14000 14% (0m 20s) 0.4489 Poshehonov / Russian ✓\n",
      "14500 14% (0m 21s) 3.7200 Sleiman / Irish ✗ (Arabic)\n",
      "15000 15% (0m 22s) 2.0546 Ustohal / Irish ✗ (Czech)\n",
      "15500 15% (0m 23s) 1.6832 Etherton / Scottish ✗ (English)\n",
      "16000 16% (0m 23s) 2.5302 Riha / Japanese ✗ (Czech)\n",
      "16500 16% (0m 24s) 1.4301 Taylor / Scottish ✓\n",
      "17000 17% (0m 25s) 2.3950 Toma / Japanese ✗ (Arabic)\n",
      "17500 17% (0m 26s) 1.3397 Granger / French ✓\n",
      "18000 18% (0m 27s) 0.4879 Qing / Chinese ✓\n",
      "18500 18% (0m 28s) 0.9445 Seo / Korean ✓\n",
      "19000 19% (0m 28s) 2.4470 Arce / Portuguese ✗ (Spanish)\n",
      "19500 19% (0m 29s) 0.2031 Takudome / Japanese ✓\n",
      "20000 20% (0m 30s) 2.7930 Silva / Czech ✗ (Portuguese)\n",
      "20500 20% (0m 31s) 1.5384 Metz / German ✓\n",
      "21000 21% (0m 32s) 1.8848 O'Connor / Greek ✗ (Irish)\n",
      "21500 21% (0m 33s) 0.8930 Valchitski / Russian ✓\n",
      "22000 22% (0m 34s) 0.6054 Esposito / Italian ✓\n",
      "22500 22% (0m 35s) 2.6494 Guerrero / Portuguese ✗ (Spanish)\n",
      "23000 23% (0m 35s) 2.2236 Patrick / Czech ✗ (Irish)\n",
      "23500 23% (0m 36s) 0.1004 Shirahata / Japanese ✓\n",
      "24000 24% (0m 37s) 2.4204 Flynn / Scottish ✗ (Irish)\n",
      "24500 24% (0m 38s) 1.8636 Said / Korean ✗ (Arabic)\n",
      "25000 25% (0m 38s) 1.5162 Beek / Dutch ✓\n",
      "25500 25% (0m 39s) 1.3198 Rademacher / German ✓\n",
      "26000 26% (0m 40s) 0.9729 Sokolof / Polish ✓\n",
      "26500 26% (0m 40s) 1.8749 Alves / Dutch ✗ (Portuguese)\n",
      "27000 27% (0m 41s) 2.0981 Clark / Czech ✗ (Scottish)\n",
      "27500 27% (0m 42s) 1.0733 Fortier / French ✓\n",
      "28000 28% (0m 42s) 3.6830 Roosa / Spanish ✗ (Dutch)\n",
      "28500 28% (0m 43s) 0.5605 Zheng / Chinese ✓\n",
      "29000 28% (0m 44s) 1.0082 Mai / Chinese ✗ (Vietnamese)\n",
      "29500 29% (0m 44s) 0.6744 Beauchene / French ✓\n",
      "30000 30% (0m 45s) 3.9055 Ransom / Arabic ✗ (Czech)\n",
      "30500 30% (0m 46s) 2.3730 Iturburua / Czech ✗ (Spanish)\n",
      "31000 31% (0m 47s) 1.5621 Korycan / Czech ✓\n",
      "31500 31% (0m 47s) 2.3587 Gadsden / Dutch ✗ (English)\n",
      "32000 32% (0m 48s) 0.8736 Davidson / Scottish ✓\n",
      "32500 32% (0m 49s) 1.4828 Varvitsiotes / Greek ✓\n",
      "33000 33% (0m 49s) 4.1752 Alexander / French ✗ (Scottish)\n",
      "33500 33% (0m 50s) 0.4791 Paloumbas / Greek ✓\n",
      "34000 34% (0m 51s) 2.2937 Jindra / Spanish ✗ (Czech)\n",
      "34500 34% (0m 51s) 1.7574 Corcoran / Scottish ✗ (English)\n",
      "35000 35% (0m 52s) 0.0751 Kaloxylos / Greek ✓\n",
      "35500 35% (0m 53s) 0.7103 Rooijakker / Dutch ✓\n",
      "36000 36% (0m 53s) 3.0197 Jonas / Greek ✗ (Czech)\n",
      "36500 36% (0m 54s) 1.5541 Pechenin / Irish ✗ (Russian)\n",
      "37000 37% (0m 55s) 0.3835 Trinh / Vietnamese ✓\n",
      "37500 37% (0m 55s) 3.8699 Hay / Chinese ✗ (Scottish)\n",
      "38000 38% (0m 56s) 1.7870 Ven / Vietnamese ✗ (Dutch)\n",
      "38500 38% (0m 57s) 1.0182 Vlasak / Czech ✓\n",
      "39000 39% (0m 57s) 1.3545 AuYong / Chinese ✓\n",
      "39500 39% (0m 58s) 2.8241 Ventura / Portuguese ✗ (Italian)\n",
      "40000 40% (0m 59s) 3.0483 Burns / Vietnamese ✗ (Scottish)\n",
      "40500 40% (1m 0s) 2.0263 Melsbach / Arabic ✗ (German)\n",
      "41000 41% (1m 0s) 0.0202 Leontarakis / Greek ✓\n",
      "41500 41% (1m 1s) 3.0727 Sachs / Portuguese ✗ (German)\n",
      "42000 42% (1m 2s) 0.3418 Bokhoven / Dutch ✓\n",
      "42500 42% (1m 2s) 0.0326 Nishimura / Japanese ✓\n",
      "43000 43% (1m 3s) 1.6665 Leroy / French ✓\n",
      "43500 43% (1m 4s) 1.9455 Prinz / Spanish ✗ (German)\n",
      "44000 44% (1m 4s) 1.0171 Zhang / Vietnamese ✗ (Chinese)\n",
      "44500 44% (1m 5s) 1.8729 Rinn / Chinese ✗ (Irish)\n",
      "45000 45% (1m 6s) 0.5727 Doan / Vietnamese ✓\n",
      "45500 45% (1m 7s) 1.5463 Armando / Italian ✗ (Spanish)\n",
      "46000 46% (1m 7s) 0.9761 Smeets / Dutch ✓\n",
      "46500 46% (1m 8s) 6.1787 Zaloumi / Italian ✗ (Greek)\n",
      "47000 47% (1m 9s) 1.2201 Sugase / Japanese ✓\n",
      "47500 47% (1m 9s) 0.6097 Banh / Vietnamese ✓\n",
      "48000 48% (1m 10s) 1.8760 Mclain / Scottish ✗ (Irish)\n",
      "48500 48% (1m 11s) 0.5256 Abbatangelo / Italian ✓\n",
      "49000 49% (1m 11s) 1.2492 Sam / Korean ✗ (Chinese)\n",
      "49500 49% (1m 12s) 0.4604 Mansour / Arabic ✓\n",
      "50000 50% (1m 13s) 1.7172 Roth / German ✓\n",
      "50500 50% (1m 13s) 0.7004 Gibson / Scottish ✓\n",
      "51000 51% (1m 14s) 0.8228 Riain / Irish ✓\n",
      "51500 51% (1m 15s) 2.4731 Smits / English ✗ (Dutch)\n",
      "52000 52% (1m 16s) 0.6438 Reiter / German ✓\n",
      "52500 52% (1m 17s) 0.7192 Mihnevich / Russian ✓\n",
      "53000 53% (1m 17s) 1.2981 Dehmel / Czech ✓\n",
      "53500 53% (1m 18s) 2.8604 Kim / Korean ✗ (Vietnamese)\n",
      "54000 54% (1m 19s) 0.3883 Campbell / Scottish ✓\n",
      "54500 54% (1m 19s) 1.7448 Sortras / Portuguese ✗ (Greek)\n",
      "55000 55% (1m 20s) 0.2210 Wilson / Scottish ✓\n",
      "55500 55% (1m 21s) 0.8317 Abaroa / Spanish ✓\n",
      "56000 56% (1m 22s) 1.8818 Kvasnicka / Japanese ✗ (Czech)\n",
      "56500 56% (1m 22s) 0.4331 Gibson / Scottish ✓\n",
      "57000 56% (1m 23s) 1.9794 Stevenson / Dutch ✗ (Scottish)\n",
      "57500 57% (1m 24s) 0.5504 Mai / Chinese ✓\n",
      "58000 57% (1m 25s) 3.0161 Golomovzy / Spanish ✗ (Russian)\n",
      "58500 58% (1m 25s) 2.7299 Abbate / French ✗ (Italian)\n",
      "59000 59% (1m 26s) 3.9400 Mclaughlin / Irish ✗ (Scottish)\n",
      "59500 59% (1m 27s) 0.2548 Dang / Vietnamese ✓\n",
      "60000 60% (1m 28s) 0.4730 Nanni / Italian ✓\n",
      "60500 60% (1m 28s) 1.1616 Chevrolet / French ✓\n",
      "61000 61% (1m 29s) 1.8238 Bang / Chinese ✗ (Korean)\n",
      "61500 61% (1m 30s) 0.1375 Abelli / Italian ✓\n",
      "62000 62% (1m 31s) 1.3881 Tang / Vietnamese ✗ (Chinese)\n",
      "62500 62% (1m 32s) 3.2434 Mclain / Scottish ✗ (Irish)\n",
      "63000 63% (1m 32s) 1.4338 Johnston / English ✗ (Scottish)\n",
      "63500 63% (1m 33s) 1.2576 Robson / Scottish ✗ (English)\n",
      "64000 64% (1m 34s) 0.7470 Ferguson / Scottish ✓\n",
      "64500 64% (1m 34s) 0.4069 Zhuo / Chinese ✓\n",
      "65000 65% (1m 35s) 1.7489 Kocian / Dutch ✗ (Czech)\n",
      "65500 65% (1m 36s) 1.9852 Sienkiewicz / Russian ✗ (Polish)\n",
      "66000 66% (1m 37s) 0.3776 Demarchis / Greek ✓\n",
      "66500 66% (1m 38s) 1.1094 Todaro / Italian ✓\n",
      "67000 67% (1m 38s) 3.4810 Oirschot / Russian ✗ (Dutch)\n",
      "67500 67% (1m 39s) 0.6812 Hong / Korean ✓\n",
      "68000 68% (1m 40s) 1.0406 Kudo / Japanese ✓\n",
      "68500 68% (1m 41s) 0.1856 Bahtigareev / Russian ✓\n",
      "69000 69% (1m 41s) 1.5632 Small / Scottish ✗ (English)\n",
      "69500 69% (1m 42s) 0.5892 Couture / French ✓\n",
      "70000 70% (1m 43s) 0.6521 Buren / Dutch ✓\n",
      "70500 70% (1m 43s) 0.0420 Mathghamhain / Irish ✓\n",
      "71000 71% (1m 44s) 1.0431 Pini / Italian ✓\n",
      "71500 71% (1m 45s) 0.0248 Piccoli / Italian ✓\n",
      "72000 72% (1m 46s) 0.0232 O'Hannigain / Irish ✓\n",
      "72500 72% (1m 46s) 0.0802 Reynders / Dutch ✓\n",
      "73000 73% (1m 47s) 1.6319 Leroy / Scottish ✗ (French)\n",
      "73500 73% (1m 48s) 4.1118 Paulis / Greek ✗ (Dutch)\n",
      "74000 74% (1m 49s) 2.6580 Chevrolet / Spanish ✗ (German)\n",
      "74500 74% (1m 49s) 2.5155 Sherman / Dutch ✗ (English)\n",
      "75000 75% (1m 50s) 2.2362 Gavalok / Polish ✗ (Czech)\n",
      "75500 75% (1m 51s) 1.0712 Phi / Korean ✗ (Vietnamese)\n",
      "76000 76% (1m 51s) 2.9749 Silva / Spanish ✗ (Portuguese)\n",
      "76500 76% (1m 52s) 1.9047 Messer / Arabic ✗ (German)\n",
      "77000 77% (1m 53s) 2.9156 Abbracciabene / French ✗ (Italian)\n",
      "77500 77% (1m 53s) 0.6549 Crespo / Portuguese ✓\n",
      "78000 78% (1m 54s) 0.7658 Ho / Vietnamese ✓\n",
      "78500 78% (1m 55s) 0.9813 Glaisyer / French ✓\n",
      "79000 79% (1m 56s) 0.3828 Bach / Vietnamese ✓\n",
      "79500 79% (1m 56s) 1.1201 Black / Scottish ✓\n",
      "80000 80% (1m 57s) 1.0521 Ondrisek / Czech ✓\n",
      "80500 80% (1m 58s) 2.6251 Sneddon / Dutch ✗ (English)\n",
      "81000 81% (1m 58s) 0.6997 Descoteaux / French ✓\n",
      "81500 81% (1m 59s) 1.3789 Niadh / Arabic ✗ (Irish)\n",
      "82000 82% (2m 0s) 0.1514 Ziemniak / Polish ✓\n",
      "82500 82% (2m 1s) 0.1368 Iitaka / Japanese ✓\n",
      "83000 83% (2m 1s) 1.2201 Aqua / Spanish ✓\n",
      "83500 83% (2m 2s) 0.7871 Bruce / Scottish ✓\n",
      "84000 84% (2m 3s) 0.3734 Gasvitsky / Russian ✓\n",
      "84500 84% (2m 3s) 0.3427 Oh  / Korean ✓\n",
      "85000 85% (2m 4s) 0.8171 Hiu / Chinese ✓\n",
      "85500 85% (2m 5s) 1.3742 Bui / Chinese ✗ (Vietnamese)\n",
      "86000 86% (2m 6s) 0.7990 D'cruz / Portuguese ✓\n",
      "86500 86% (2m 6s) 0.7111 Szewc / Polish ✓\n",
      "87000 87% (2m 7s) 0.0809 O'Mooney / Irish ✓\n",
      "87500 87% (2m 8s) 0.1346 Turchi / Italian ✓\n",
      "88000 88% (2m 8s) 0.3265 La / Vietnamese ✓\n",
      "88500 88% (2m 9s) 3.6103 Duggan / Irish ✗ (English)\n",
      "89000 89% (2m 10s) 1.7595 Sparkes / Dutch ✗ (English)\n",
      "89500 89% (2m 10s) 2.0944 Finn / Chinese ✗ (Irish)\n",
      "90000 90% (2m 11s) 0.9929 Lobo / Portuguese ✓\n",
      "90500 90% (2m 12s) 3.0742 Belin / Irish ✗ (Russian)\n",
      "91000 91% (2m 13s) 0.7246 Schroeter / German ✓\n",
      "91500 91% (2m 13s) 0.2464 Gonzalez / Spanish ✓\n",
      "92000 92% (2m 14s) 0.4490 Bosko / Polish ✓\n",
      "92500 92% (2m 15s) 2.5038 Harman / Arabic ✗ (French)\n",
      "93000 93% (2m 15s) 0.3274 Bohler / German ✓\n",
      "93500 93% (2m 16s) 1.9425 Durante / Italian ✗ (Spanish)\n",
      "94000 94% (2m 17s) 0.6128 Herbert / German ✓\n",
      "94500 94% (2m 17s) 0.2166 Man / Chinese ✓\n",
      "95000 95% (2m 18s) 0.2261 Choe / Korean ✓\n",
      "95500 95% (2m 19s) 0.7995 Hanania / Arabic ✓\n",
      "96000 96% (2m 19s) 1.7163 Schreck / Czech ✗ (German)\n",
      "96500 96% (2m 20s) 0.2107 Babetov / Russian ✓\n",
      "97000 97% (2m 21s) 1.4865 Sabbagh / Portuguese ✗ (Arabic)\n",
      "97500 97% (2m 21s) 3.4430 Mojjis / Arabic ✗ (Czech)\n",
      "98000 98% (2m 22s) 7.3144 Charlott / Scottish ✗ (Czech)\n",
      "98500 98% (2m 23s) 0.6059 Christie / Scottish ✓\n",
      "99000 99% (2m 24s) 1.0212 Serafim / Portuguese ✓\n",
      "99500 99% (2m 24s) 0.6756 Voclain / French ✓\n",
      "100000 100% (2m 25s) 1.5697 Pender / German ✗ (English)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 500\n",
    "plot_every = 10000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As ONNX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = lineToTensor('Jones')[0]\n",
    "hidden = rnn.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%name : Float(1, 57)\n",
      "      %1 : Float(1, 128)\n",
      "      %2 : Float(128, 185)\n",
      "      %3 : Float(128)\n",
      "      %4 : Float(18, 185)\n",
      "      %5 : Float(18)) {\n",
      "  %6 : Float(1, 185) = onnx::Concat[axis=1](%name, %1), scope: RNN\n",
      "  %7 : Float(1, 128) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%6, %2, %3), scope: RNN/Linear[i2h]\n",
      "  %8 : Float(1, 18) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%6, %4, %5), scope: RNN/Linear[i2o]\n",
      "  %origin : Float(1, 18) = onnx::LogSoftmax[axis=1](%8), scope: RNN/LogSoftmax[softmax]\n",
      "  return (%origin, %7);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model=rnn,\n",
    "                  args=(dummy_input, hidden), \n",
    "                  f=str(PurePath(bundle_root, 'common/char-rnn-classification.onnx')),\n",
    "                  verbose=True,\n",
    "                  input_names=['name'], output_names=['origin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(rnn, str(PurePath(bundle_root, 'common/char-rnn-classification.pth')))\n",
    "torch.save(rnn.state_dict(), str(PurePath(bundle_root, 'common/char-rnn-classification.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As tensorflow lite (smallest size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Acos in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Asin in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Atan in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:74: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Cos in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Expand in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Sin in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/opt/conda/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:71: UserWarning: Fail to get since_version of Tan in domain `` with max_inclusive_version=6. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf\n",
    "model = prepare(onnx.load(str(PurePath(bundle_root, 'common/char-rnn-classification.onnx'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read with Caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install caffe2\n",
    "import caffe2.python.onnx.backend as backend\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the Results\n",
    "--------------------\n",
    "\n",
    "Plotting the historical loss from ``all_losses`` shows the network\n",
    "learning:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd242bc3cf8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Results\n",
    "======================\n",
    "\n",
    "To see how well the network performs on different categories, we will\n",
    "create a confusion matrix, indicating for every actual language (rows)\n",
    "which language the network guesses (columns). To calculate the confusion\n",
    "matrix a bunch of samples are run through the network with\n",
    "``evaluate()``, which is the same as ``train()`` minus the backprop.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "#ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "#ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick out bright spots off the main axis that show which\n",
    "languages it guesses incorrectly, e.g. Chinese for Korean, and Spanish\n",
    "for Italian. It seems to do very well with Greek, and very poorly with\n",
    "English (perhaps because of overlap with other languages).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on User Input\n",
    "---------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Dovesky\n",
      "(-0.83) Russian\n",
      "(-1.37) Czech\n",
      "(-1.90) English\n",
      "\n",
      "> Jackson\n",
      "(-0.30) Scottish\n",
      "(-2.12) English\n",
      "(-3.32) Czech\n",
      "\n",
      "> Satoshi\n",
      "(-1.21) Japanese\n",
      "(-1.46) Arabic\n",
      "(-1.87) Polish\n"
     ]
    }
   ],
   "source": [
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Nikolas\n",
      "(-0.47) Greek\n",
      "(-2.22) Czech\n",
      "(-2.44) Polish\n"
     ]
    }
   ],
   "source": [
    "predict('Nikolas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final versions of the scripts `in the Practical PyTorch\n",
    "repo <https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__\n",
    "split the above code into a few files:\n",
    "\n",
    "-  ``data.py`` (loads files)\n",
    "-  ``model.py`` (defines the RNN)\n",
    "-  ``train.py`` (runs training)\n",
    "-  ``predict.py`` (runs ``predict()`` with command line arguments)\n",
    "-  ``server.py`` (serve prediction as a JSON API with bottle.py)\n",
    "\n",
    "Run ``train.py`` to train and save the network.\n",
    "\n",
    "Run ``predict.py`` with a name to view predictions:\n",
    "\n",
    "::\n",
    "\n",
    "    $ python predict.py Hazaki\n",
    "    (-0.42) Japanese\n",
    "    (-1.39) Polish\n",
    "    (-3.51) Czech\n",
    "\n",
    "Run ``server.py`` and visit http://localhost:5533/Yourname to get JSON\n",
    "output of predictions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
